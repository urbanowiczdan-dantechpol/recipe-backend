# ğŸš€ Recipe Unifier Backend

Backend API dla Recipe Unifier - AI-powered recipe parser using OpenAI GPT.

## ğŸ“‹ Quick Start

### 1. Instalacja zaleÅ¼noÅ›ci

```bash
npm install
```

### 2. Konfiguracja zmiennych Å›rodowiskowych

Skopiuj plik przykÅ‚adowy i dodaj swÃ³j klucz OpenAI:

```bash
cp .env.local.example .env.local
```

Edytuj `.env.local` i zamieÅ„ `sk-your-openai-api-key-here` na prawdziwy klucz OpenAI.

**Pobierz klucz OpenAI:**
1. IdÅº do: https://platform.openai.com/api-keys
2. Zaloguj siÄ™ / Zarejestruj
3. Kliknij "Create new secret key"
4. Skopiuj klucz (zaczyna siÄ™ od `sk-...`)
5. Wklej do `.env.local`

### 3. Uruchom serwer deweloperski

```bash
npm run dev
```

Backend bÄ™dzie dostÄ™pny pod: http://localhost:3000

### 4. Test health check

OtwÃ³rz w przeglÄ…darce:
```
http://localhost:3000/api/health
```

Lub w terminalu:
```bash
curl http://localhost:3000/api/health
```

PowinieneÅ› zobaczyÄ‡:
```json
{
  "status": "healthy",
  "service": "recipe-unifier-backend",
  "version": "1.0.0",
  "timestamp": "2024-...",
  "openai_configured": true
}
```

### 5. Test parsowania przepisu

```bash
curl -X POST http://localhost:3000/api/parse \
  -H "Content-Type: application/json" \
  -d '{"url": "https://www.kwestiasmaku.com/przepis/nalesniki"}'
```

## ğŸš¢ Deployment na Vercel

### Pierwszy deploy:

```bash
# 1. Zainstaluj Vercel CLI (jeÅ›li nie masz)
npm install -g vercel

# 2. Login
vercel login

# 3. Deploy
vercel
```

### Dodaj zmienne Å›rodowiskowe w Vercel:

1. IdÅº do: https://vercel.com/dashboard
2. Wybierz projekt `recipe-unifier-backend`
3. Settings â†’ Environment Variables
4. Dodaj:
   - Name: `OPENAI_API_KEY`
   - Value: `sk-your-key-here`
   - Environment: Production, Preview, Development
5. Save

### Production deploy:

```bash
vercel --prod
```

Otrzymasz URL typu: `https://recipe-unifier-backend.vercel.app`

### Zaktualizuj frontend:

W projekcie frontendowym edytuj `js/config.js`:

```javascript
const CONFIG = {
    BACKEND_URL: 'https://recipe-unifier-backend.vercel.app',
    // ...
};
```

## ğŸ“ Struktura projektu

```
backend/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ parse/
â”‚       â”‚   â””â”€â”€ route.ts      # GÅ‚Ã³wny endpoint parsowania
â”‚       â””â”€â”€ health/
â”‚           â””â”€â”€ route.ts      # Health check endpoint
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ types.ts              # TypeScript interfaces
â”‚   â”œâ”€â”€ scraper.ts            # Web scraping logic
â”‚   â””â”€â”€ openai.ts             # OpenAI integration
â”œâ”€â”€ .env.local                # Zmienne Å›rodowiskowe (NIE commituj!)
â”œâ”€â”€ .env.local.example        # PrzykÅ‚adowy plik env
â”œâ”€â”€ package.json              # ZaleÅ¼noÅ›ci
â”œâ”€â”€ tsconfig.json             # TypeScript config
â””â”€â”€ next.config.js            # Next.js config
```

## ğŸ”Œ API Endpoints

### POST /api/parse

Parsuj przepis z URL.

**Request:**
```json
{
  "url": "https://example.com/recipe"
}
```

**Response (Success 200):**
```json
{
  "title": "Nazwa przepisu",
  "author": "Autor",
  "ingredients": [
    {
      "quantity": 2,
      "unit": "szt",
      "name": "jajka",
      "notes": ""
    }
  ],
  "steps": [
    {
      "step_number": 1,
      "instruction": "ZrÃ³b coÅ›...",
      "time_minutes": 5
    }
  ],
  "prep_time": 15,
  "cook_time": 30,
  "total_time": 45,
  "servings": 4,
  "difficulty": "easy",
  "category": "breakfast",
  "language": "pl",
  "tags": ["szybkie"],
  "_meta": {
    "processing_time_ms": 12000,
    "content_length": 5000
  }
}
```

**Response (Error 400/500):**
```json
{
  "error": "Error message here"
}
```

### GET /api/health

SprawdÅº status backendu.

**Response:**
```json
{
  "status": "healthy",
  "service": "recipe-unifier-backend",
  "version": "1.0.0",
  "timestamp": "2024-12-07T12:00:00.000Z",
  "openai_configured": true
}
```

## ğŸ› Troubleshooting

### "OpenAI API error"
- SprawdÅº czy `OPENAI_API_KEY` jest poprawny w `.env.local`
- SprawdÅº saldo na: https://platform.openai.com/usage

### "CORS error"
- CORS jest skonfigurowany na `*` (wszystkie origins)
- JeÅ›li problem, sprawdÅº czy backend zwraca header: `Access-Control-Allow-Origin: *`

### "Module not found"
```bash
rm -rf node_modules package-lock.json
npm install
```

### Cold start (pierwsze wywoÅ‚anie wolne)
- To normalne na Vercel (serverless functions)
- Pierwsze wywoÅ‚anie: ~30s
- Kolejne: ~10-15s

## ğŸ’° Koszty

- **Vercel Hosting:** $0 (100k requests/month free)
- **OpenAI GPT-4o-mini:** ~$0.15 per 1M tokens
  - 1 przepis â‰ˆ 5k tokens â‰ˆ $0.0008 (< 1 cent)
  - 100 przepisÃ³w â‰ˆ $0.08
- **OpenAI GPT-4o:** ~$2.50 per 1M tokens (10x droÅ¼szy, lepsza jakoÅ›Ä‡)

**Total:** $0-5/miesiÄ…c dla osobistego uÅ¼ytku

## ğŸ”’ BezpieczeÅ„stwo

- âœ… API key w zmiennych Å›rodowiskowych (nie w kodzie)
- âœ… `.env.local` w `.gitignore` (nie commituj kluczy!)
- âœ… Rate limiting (Vercel default)
- âœ… Input validation (URL format)
- âœ… Error handling (bez exposowania stack traces w production)

## ğŸ“š WiÄ™cej informacji

Zobacz gÅ‚Ã³wny README projektu frontendowego dla peÅ‚nej dokumentacji.

## ğŸ†˜ Support

Masz problem? SprawdÅº:
1. `FAQ.md` w projekcie frontendowym
2. Logi Vercel Dashboard
3. Console w DevTools (F12)

---

**Zbudowane z â¤ï¸ i OpenAI GPT**
